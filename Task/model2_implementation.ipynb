{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 > Offensive Language Classification </h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all necessary library\n",
    "import pandas as pd\n",
    "import langdetect\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from collections import Counter\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertTokenizer, BertModel, get_scheduler\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, roc_curve, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all CSV file\n",
    "train =pd.read_csv(\"../offence_data/train.csv\")\n",
    "test = pd.read_csv(\"../offence_data/test.csv\")\n",
    "valid = pd.read_csv(\"../offence_data/validation.csv\") \n",
    "test_lebel = pd.read_csv(\"../offence_data/test_labels.csv\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 > just visualize train , test, validation data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lebel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: green;\"> adding test label into test data and drop where lebel is NAN  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Index'] = range(1, len(test) + 1)\n",
    "test_lebel['Index'] = range(1, len(test_lebel) + 1)\n",
    "test = test.merge(test_lebel[['Index', 'toxic']], on='Index', how='left')\n",
    "test.drop('Index', axis=1, inplace=True)\n",
    "test['toxic'] = test['toxic'].dropna()\n",
    "test = test.dropna(subset=['toxic'])\n",
    "test['toxic'] = test['toxic'].astype(int)\n",
    "test = test.rename(columns={'content': 'feedback_text'})\n",
    "print(test.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: green;\"> Start EDA and Data manipulation   </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lebel destribuition chart\n",
    "label_cols = ['toxic', 'abusive', 'vulgar', 'menace', 'offense', 'bigotry']\n",
    "train[label_cols].sum().plot(kind=\"bar\", title=\"Label Distribution\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Detect laguages present in train dataset </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect, LangDetectException\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame (replace this with your real one)\n",
    "# train = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Create a list to hold detected languages\n",
    "detected_languages = []\n",
    "\n",
    "# Iterate through each feedback text\n",
    "for text in train['feedback_text']:\n",
    "    if pd.isna(text):\n",
    "        detected_languages.append(None)\n",
    "    else:\n",
    "        try:\n",
    "            lang = detect(text)\n",
    "            detected_languages.append(lang)\n",
    "        except LangDetectException:\n",
    "            detected_languages.append(None)  # Or use a default like 'unknown'\n",
    "\n",
    "# Add the language column to the DataFrame\n",
    "train['lang'] = detected_languages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['lang'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['lang'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna(subset=['lang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = ' '.join(train['lang'].astype(str)).lower().split()\n",
    "\n",
    "\n",
    "common_words = Counter(all_words)\n",
    "common_words_df = pd.DataFrame(common_words.most_common(20), columns=['word', 'count'])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(data=common_words_df, x='count', y='word', palette='mako')\n",
    "plt.title(\"Top 20 Most Common Language in training set\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Word\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>collecting multi langual stop word for further analisys </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# List of language names (without language codes)\n",
    "languages = [\n",
    "    'english', 'spanish', 'tagalog', 'estonian', 'german', 'persian (farsi)', 'afrikaans',\n",
    "    'norwegian', 'somali', 'indonesian', 'french', 'vietnamese', 'slovenian', 'turkish',\n",
    "    'portuguese', 'romanian', 'swahili', 'croatian', 'danish', 'albanian', 'welsh', 'italian',\n",
    "    'czech', 'swedish', 'finnish', 'dutch', 'arabic', 'polish', 'bengali', 'catalan', 'hungarian',\n",
    "    'lithuanian', 'slovak', 'russian', 'hebrew', 'korean', 'chinese (simplified)', 'gujarati', \n",
    "    'tamil', 'greek', 'hindi', 'thai', 'latvian', 'macedonian', 'malayalam', 'chinese (traditional)',\n",
    "    'telugu', 'marathi', 'bulgarian'\n",
    "]\n",
    "\n",
    "multi_stop_words = set()\n",
    "\n",
    "# Loop through the list of languages and update the multi_stop_words set\n",
    "for lang in languages:\n",
    "    try:\n",
    "        # Check if stopwords exist for the language\n",
    "        if lang in stopwords.fileids():\n",
    "            multi_stop_words.update(stopwords.words(lang))\n",
    "        else:\n",
    "            print(f\"No stopwords available for: {lang}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error with language {lang}: {e}\")\n",
    "\n",
    "print(f\"Collected {len(multi_stop_words)} stopwords.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check for Missing Values\n",
    "print(\"Missing values:\\n\", train.isnull().sum())\n",
    "\n",
    "# Plot bar chart for missing values\n",
    "missing_counts = train.isnull().sum()\n",
    "missing_counts = missing_counts[missing_counts >= 0]  \n",
    "\n",
    "if not missing_counts.empty:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(x=missing_counts.index, y=missing_counts.values, palette=\"rocket\")\n",
    "    plt.title(\"Missing Values per Column\")\n",
    "    plt.ylabel(\"Number of Missing Values\")\n",
    "    plt.xlabel(\"Column Name\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Drop rows with missing feedback_text if any\n",
    "missing_texts = train[train['feedback_text'].isnull()]\n",
    "print(f\"\\nRows with missing feedback_text: {len(missing_texts)}\")\n",
    "if len(missing_texts) > 0:\n",
    "    train = train.dropna(subset=['feedback_text'])\n",
    "\n",
    "# Word Distribution and Sentence Length\n",
    "\n",
    "train['word_count'] = train['feedback_text'].apply(lambda x: len(str(x).split()))\n",
    "train['char_count'] = train['feedback_text'].apply(lambda x: len(str(x)))\n",
    "\n",
    "# Plot histograms\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "sns.histplot(train['word_count'], bins=50, ax=axes[0], color='skyblue')\n",
    "axes[0].set_title('Word Count Distribution')\n",
    "\n",
    "sns.histplot(train['char_count'], bins=50, ax=axes[1], color='salmon')\n",
    "axes[1].set_title('Character Count Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Most Common Words (Before Preprocessing)\n",
    "\n",
    "\n",
    "# Get the list of English stopwords\n",
    "# Remove stop words from feedback_text\n",
    "all_words = ' '.join(train['feedback_text'].astype(str)).lower().split()\n",
    "filtered_words = [word for word in all_words if word not in multi_stop_words]\n",
    "\n",
    "# Count the most common words\n",
    "common_words = Counter(filtered_words)\n",
    "common_words_df = pd.DataFrame(common_words.most_common(20), columns=['word', 'count'])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(data=common_words_df, x='count', y='word', palette='mako')\n",
    "plt.title(\"Top 20 Most Common Words (after removing multi langual  Stopwords only)\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Word\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to clean the text (remove stopwords, punctuation, numbers, etc.)\n",
    "def clean_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuation using str.translate\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Remove numbers and special characters using regular expressions\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    words = text.split()\n",
    "    cleaned_words = [word for word in words if word not in multi_stop_words ]\n",
    "\n",
    "    return ' '.join(cleaned_words)\n",
    "\n",
    "# Apply the clean_text function to the feedback_text column\n",
    "train['cleaned_feedback_text'] = train['feedback_text'].apply(lambda x: clean_text(str(x)))\n",
    "\n",
    "# Combine all cleaned words\n",
    "all_words = ' '.join(train['cleaned_feedback_text']).split()\n",
    "\n",
    "# Count the most common words\n",
    "common_words = Counter(all_words)\n",
    "common_words_df = pd.DataFrame(common_words.most_common(20), columns=['word', 'count'])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(data=common_words_df, x='count', y='word', palette='mako')\n",
    "plt.title(\"Top 20 Most Common Words (After removing stopword and other text noise)\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Word\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: green;\"> Word Frequency Map  </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# Combine all feedback_text into one string\n",
    "all_text = ' '.join(train['feedback_text'].astype(str)).lower()\n",
    "\n",
    "# Generate Word Cloud\n",
    "wordcloud = WordCloud(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    background_color='white',\n",
    "    stopwords=multi_stop_words,\n",
    "    max_words=200,\n",
    "    colormap='plasma'\n",
    ").generate(all_text)\n",
    "\n",
    "# Plot Word Cloud\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"ðŸ”¤ Word Frequency Map (Word Cloud)\", fontsize=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> balancing the  dataset </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#badly needed but donot get time to do it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>preprocessing , training , evaluation using multilangual pretrained model  bert-base-multilingual-cased <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# NLTK setup\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "# Preprocessing\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
    "    text = re.sub(r'@\\w+|\\#', '', text)\n",
    "    text = re.sub(rf\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "# Load Data\n",
    "\n",
    "train_df = train\n",
    "val_df = valid\n",
    "test_df = test\n",
    "\n",
    "# Apply preprocessing\n",
    "train_df['feedback_text'] = train_df['feedback_text'].apply(preprocess)\n",
    "val_df['feedback_text'] = val_df['feedback_text'].apply(preprocess)\n",
    "test_df['feedback_text'] = test_df['feedback_text'].apply(preprocess)\n",
    "\n",
    "# Label columns\n",
    "label_cols = ['toxic', 'abusive', 'vulgar', 'menace', 'offense', 'bigotry']\n",
    "\n",
    "\n",
    "# Tokenization and Dataset\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "\n",
    "class ToxicDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = tokenizer(\n",
    "            self.texts[idx],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "train_dataset = ToxicDataset(train_df['feedback_text'].tolist(), train_df[label_cols].values.tolist())\n",
    "val_dataset = ToxicDataset(val_df['feedback_text'].tolist(), val_df[['toxic']].values.tolist())\n",
    "test_dataset = ToxicDataset(test_df['feedback_text'].tolist(), test_df[['toxic']].values.tolist())\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "\n",
    "# Model\n",
    "\n",
    "class ToxicClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, 6)  # 6 labels\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = self.dropout(output.pooler_output)\n",
    "        return torch.sigmoid(self.fc(pooled_output))\n",
    "\n",
    "\n",
    "# Training Setup\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ToxicClassifier().to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "epochs = 1\n",
    "loss_fn = nn.BCELoss()\n",
    "total_steps = len(train_loader) * epochs\n",
    "scheduler = get_scheduler(\"linear\", optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "\n",
    "# Training Loop\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# Validation Evaluation (TOXIC only)\n",
    "model.eval()\n",
    "val_preds, val_trues = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].cpu().numpy()\n",
    "        outputs = model(input_ids, attention_mask).cpu().numpy()\n",
    "        val_preds.extend(outputs[:, 0])  # Only TOXIC\n",
    "        val_trues.extend(labels[:, 0])  # Only TOXIC\n",
    "\n",
    "val_preds = np.array(val_preds)\n",
    "val_trues = np.array(val_trues)\n",
    "val_bin_preds = (val_preds >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\n Validation Classification Report (TOXIC only):\")\n",
    "print(classification_report(val_trues, val_bin_preds))\n",
    "print(\"AUC:\", roc_auc_score(val_trues, val_preds))\n",
    "\n",
    "# ROC curve for TOXIC\n",
    "fpr, tpr, _ = roc_curve(val_trues, val_preds)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=\"TOXIC AUC = %0.4f\" % auc(fpr, tpr))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (TOXIC - Validation)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix for Test Set\n",
    "sns.heatmap(confusion_matrix(val_trues, val_bin_preds), annot=True, fmt=\"d\", cmap=\"Greens\")\n",
    "plt.title(\"Confusion Matrix - valid Set (Toxic)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Prediction (TOXIC Only)\n",
    "t_preds, t_trues = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].cpu().numpy()\n",
    "        outputs = model(input_ids, attention_mask).cpu().numpy()\n",
    "        t_preds.extend(outputs[:, 0])  # Only TOXIC\n",
    "        t_trues.extend(labels[:, 0])  # Only TOXIC\n",
    "\n",
    "t_preds = np.array(t_preds)\n",
    "t_trues = np.array(t_trues)\n",
    "t_bin_preds = (t_preds >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\n Validation Classification Report (TOXIC only):\")\n",
    "print(classification_report(t_trues, t_bin_preds))\n",
    "print(\"AUC:\", roc_auc_score(t_trues, t_preds))\n",
    "\n",
    "# ROC curve for TOXIC\n",
    "fpr, tpr, _ = roc_curve(t_trues, t_preds)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=\"TOXIC AUC = %0.4f\" % auc(fpr, tpr))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (TOXIC - Test)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix for Test Set\n",
    "sns.heatmap(confusion_matrix(t_trues, t_bin_preds), annot=True, fmt=\"d\", cmap=\"Greens\")\n",
    "plt.title(\"Confusion Matrix - Test Set (Toxic)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "offence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
